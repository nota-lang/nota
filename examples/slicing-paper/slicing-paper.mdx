import "@wcrichto/nota/dist/nota.css";
import "@wcrichto/nota-theme-acm/dist/nota-theme-acm.css";
import bibtex from "./slicing-paper.bib";
import { SliceListing, Principle } from "./components";
import { SyntaxDiagram } from "./diagrams";
import { Oxide, OxideExtra } from "./language";
import { rust } from "@codemirror/lang-rust";

<Document>
<ListingConfigure language={rust()} />
<Title>Modular Program Slicing Through Ownership</Title>
<Authors>
  <Author>
    <Name value="Will Crichton" />
    <Affiliation>
      <Institution value="Stanford University" />
    </Affiliation>
  </Author>
  <Author>
    <Name value="Marco Patrignani" />
    <Affiliation>
      <Institution value="CISPA Helmholtz Center for Information Security" />
    </Affiliation>
  </Author>
  <Author>
    <Name value="Maneesh Agrawala" />
    <Affiliation>
      <Institution value="Stanford University" />
    </Affiliation>
  </Author>
  <Author>
    <Name value="Pat Hanrahan" />
    <Affiliation>
      <Institution value="Stanford University" />
    </Affiliation>
  </Author>
</Authors>
<Abstract>
  Program slicing, or identifying the subset of a program relevant to a value, relies on understanding the dataflow of a program. In languages with mutable pointers and functions like C or Java, tracking dataflow has historically required whole-program analysis, which can be be slow and challenging to integrate in practice. Advances in type systems have shown how to modularly track dataflow through the concept of ownership. We demonstrate that ownership can modularize program slicing by using types to compute a provably sound and reasonably precise approximation of mutation. We present an algorithm for slicing Oxide, a formalized ownership-based language, and prove the algorithm's soundness as a form of noninterference. Then we describe an implementation of the algorithm for the Rust programming language, and show empirically that modular slices are the same as whole-program slices in 95.4% of slices drawn from large Rust codebases.
</Abstract>

$$
\newcommand{\textsc}[1]{\text{\tiny #1}}
\newcommand{\msf}[1]{\mathsf{#1}}
\newcommand{\tc}[6]{{#1}; {#2}; {#3} \vdash {#4} : {#5} \Rightarrow {#6}}
\newcommand{\ownsafe}[5]{{#1}; {#2} \vdash_{#3} {#4} \Rightarrow {#5}}
\newcommand{\subtype}[5]{{#1}; {#2} \vdash {#3} \mathrel{\footnotesize \lesssim} {#4} \Rightarrow {#5}}
\newcommand{\stepsto}[5]{{#1} \vdash ({#2};~{#3}) \rightarrow ({#4};~{#5})}
\newcommand{\evalsto}[5]{{#1} \vdash ({#2};~{#3}) \overset{\footnotesize\ast}{\rightarrow} ({#4};~{#5})}
\newcommand{\stack}[0]{\sigma}
\newcommand{\pctx}[2]{{#1}^{\tiny\square}[{#2}]}
\newcommand{\valuectx}[0]{\mathcal{V}}
\newcommand{\valueplug}[2]{{#1}[{#2}]}
\newcommand{\pointsto}[4]{{#1} \vdash {#2} \Downarrow {#3} \times {#4}}
\newcommand{\notdisjoint}[2]{{#1} \sqcap {#2}}
\newcommand{\disjoint}[2]{{#1} \mathrel{\#} {#2}}
\newcommand{\refs}[2]{{#1}\text{-}\mathsf{refs}({#2})}
\newcommand{\ownqleq}[2]{{#1} \lesssim {#2}}
\newcommand{\stackeq}[3]{{#1} \mathrel{\overset{#3}{\sim}} {#2}}
\newcommand{\allplaces}[2]{\msf{all}\text{-}\msf{places}({#1}, {#2})}
\newcommand{\setof}[1]{\{\overline{#1}\}}
\newcommand{\stepped}[1]{\vec{#1}}
\newcommand{\link}[2]{\htmlClass{link type-#1}{#2}}
\newcommand{\eqdef}{~\mathrel{\overset{\msf{def}}{=}}~}
$$

<Oxide.Commands />
<OxideExtra.Commands />

$$
\newcommand{\uty}{\tybnum}
\newcommand{\eref}[3]{\tysref{#2}{#1}{#3}}
\newcommand{\uniq}{\ownquniq}
\newcommand{\shrd}{\ownqshrd}
\renewcommand{\r}{\concrprov}
\newcommand{\loanset}{\setof{\loan}}
\newcommand{\sty}{\msf{String}}
\newcommand{\mut}{\msf{mut}}
\newcommand{\any}{\msf{any}}
\newcommand{\arrg}{\msf{arg}}
\newcommand{\reff}{\msf{ref}}
$$

<Section title="Introduction" name="sec:intro">  
Program slicing is the task of identifying the subset of a program relevant to computing a value of interest. The concept of slicing was introduced 40 years ago when @[weiser1982programmers; full] demonstrated that programmers mentally construct slices while debugging. Since then, hundreds of papers have been published on implementing automated program slice, as surveyed by @[xu2005brief; full] and @[silva2012vocabulary; full]. Despite these efforts, a review of slicers found "slicing-based debugging techniques are rarely used in practice" @[parnin2011automated]@[footnote:1].

[^1]: The only open-source, functioning slicers the authors could find are Frama-C @[cuoq2012frama] and dg @[llvmslicer]. Slicing tools for Java like Kaveri @[jayaraman2005kaveri] no longer work. The most industrial-strength slicing tool, CodeSurfer @[balakrishnan2005codesurfer] was GrammaTech's proprietary technology and appears to no longer exist.

A major challenge for slicing is addressing the underlying program analysis problems. At a high level, slicing is about dataflow --- if $x$ is relevant, then any means by which data flows into $x$ are also relevant. In today's programming languages, analyzing dataflow is difficult because of the interaction of two features: functions and pointers. For example, imagine slicing a value in a function $f$ which calls a function $g$. In a language without side-effects, then the only relevance $g$ could possibly have in $f$ is its return value. But in a language that allows effects such as mutation on pointers, $g$ could modify data used within $f$, requiring a pointer analysis. Moreover, if $f$ is a higher-order function parameterized on $g$, then the slice must consider all the possible functions that $g$ could be, i.e. control-flow analysis.

The standard solution for analyzing programs with pointers and functions is _whole-program analysis_. That is, for a given function of interest, analyze the definitions of all of the function's callers and callees in the current codebase. However, whole-program analysis suffers from a few logistical and conceptual issues:

* _Analysis time scales with the size of the whole program:_ the time complexity of whole-program analysis scales either polynomially or exponentially with the number of call sites in the program, depending on context-sensitivity @[might2010resolving]. In practice, this means more complex codebases can take substantially longer to analyze. For
  instance, the recent PSEGPT pointer analysis tool @[zhao2018parallel] takes 1 second on a codebase of 282,000 lines of code and 3 minutes on a codebase of 2.2 million lines of code.
* _Analysis requires access to source code for the whole program:_ an assumption of analyzing a whole program is that a whole program is actually accessible. However, many programs use libraries that are shipped as pre-compiled objects with no source code, either for reasons of efficiency or intellectual property.
* _Analysis results are anti-modular:_ when analyzing a particular function, relying on calling contexts to analyze the function's inputs means that any results are not universal. Calling-context-sensitive analysis determine whether two pointers alias _in the context of the broader codebase_, so alias analysis results can change due to modifications in code far away from the current module.

These issues are not new --- @[rountev1999data; full] and @[cousot2002modular; full] observed the same two decades ago when arguing for modular static analysis. The key insight arising from their research is that static analysis can be modularized by computing _symbolic procedure summaries_. For instance, @[yorsh2008generating; full] show how to automatically summarize which inputs and outputs are possibly null for a given Java function. The analysis is modular because a function's summary can be computed only given the summaries, and not definitions, of callees in the function. In such prior work, the language of symbolic procedure summaries has been defined in a separate formal system from the programming language being analyzed, such as the micro-transformer framework of @[yorsh2008generating; full].

Our work begins with the observation: _function type signatures are symbolic procedure summaries_. The more expressive a language's type system, the more behavior that can be summarized by a type. Nearly all work on program slicing, dataflow analysis, and procedure summaries has operated on C, Java, or equivalents. These languages have impoverished type systems, and so any interesting static analysis requires a standalone abstract interpreter. However, if a language's type system were expressive enough to encode information about dataflow, then a function's type signature could be used to reason about the aliasing and side effects needed for slicing. Moreover, a function's type signature is required information for a compiler to export when
building a library. Using the type system for dataflow analysis therefore obviates the logistical challenge of integrating an external analysis tool into a complex build system.

Today, the primary technique for managing dataflow with types is _ownership_. Ownership is a concept that has emerged from several intersecting lines of research on linear logic @[girard1987linear], class-based alias management @[clarke1998ownership], and region-based memory management @[grossman2002region]. Generally, ownership refers to a system where values are owned by an entity, which can temporarily or permanently transfer ownership to other entities. The type system then statically tracks the flow of ownership between entities. Ownership-based type systems enforce the invariant that values are not simultaneously aliased and mutated, either for the purposes of avoiding memory errors, data races, or abstraction violations.

Our thesis is that ownership can modularize program slicing by using types to compute a provably sound and reasonably precise approximation of the necessary dataflow information. We build this thesis in five parts:

1. We provide an intuition for the relationship between ownership and slicing by describing how ownership works in Rust, the only industrial-grade ownership-based programming language today (@[sec:background]).
2. We formalize an algorithm for modular static slicing as an extension to the type system of Oxide @[weiss2019oxide], a formal model of Rust's static and dynamic semantics (@[sec:model] and @[sec:algorithm]).
3. We prove the soundness of this algorithm as a form of noninterference, building on the connection between slicing and information flow established by @[abadi1999core; full] (@[sec:soundness] and @[sec:appendix]).
4. We describe an implementation of the slicing algorithm for Rust, translating the core insights of the algorithm to work on a lower-level control-flow graph (@[sec:implementation])
5. We evaluate the precision of the modular Rust slicer against a whole-program slicer on a dataset of 10 codebases with a total of 280k LOC. We find that modular slices are the same size as whole-program slices 95.4% of the time, and are on average 7.6% larger in the remaining 4.6% of cases (@[sec:evaluation]).
</Section>

<Section title="Principles" name="sec:background">
A backwards static slice is the subset of a program that could influence a particular value (backwards) under any possible execution (static). A slice is defined with respect to a slicing criterion, which is a variable at a particular point in a program. In this section, we provide an intuition for how slices interact with different features of the Rust programming language, namely: places (@[sec:places]), references (@[sec:pointers]), function calls (@[sec:funcalls]), and interior mutability (@[sec:intmut]).

<SubSection title="Places" name="sec:places">
<Wrap align="right">
<SliceListing
  code={`let mut x = 1;
let y = 2;
let z = 3;
x = y;
println!("{}", @x@);`}
/>
</Wrap>

A place is a reference to a concrete piece of data in memory, like a variable `x` or path into a data structure `x.field`. Slices on places are defined by bindings, mutation, and control flow.

For instance, the Rust snippet on the right shows the slice in orange of a place in green. The assignment `x = y` means `y` is relevant for the slice, so the statement `let y = 2` is relevant as well. Because `z` is not used in the computation of `x`, then `let z = 3`. is not relevant. Additionally, because `x = y` overwrites the previous value of `x`, then the original assignment `x = 1` is not relevant either.

<Wrap align="left">
  <SliceListing
    code={`let mut x = 1;
let mut y = 2;
if y > 0 { x = 3; } 
else     { y = 4; }
println!("{}", @x@);`}
  />
</Wrap>

If a mutation is conditioned on a predicate (as in line 3 in the snippet on the left) then the predicate is relevant to the mutated place. In this example, because `x = 3` is only executed if `y > 0`, then the value of `y` (at the time-of-check) is relevant to the value of `x`.

Slices on composite data structures are defined by whether a mutation conflicts with a particular path into the data structure. For example, consider slicing on a tuple as in the three snippets below (note that `t.n` gets the $n$-th field of the tuple `t`):

<Row>
  <SliceListing
    code={`let mut t = (0, 1, 2);
t = (3, 4, 5);
t.0 = 6;
t.1 = 7;
println!("{:?}", @t@);`}
  />
  <SliceListing
    code={`let mut t = (0, 1, 2);
t = (3, 4, 5);
t.0 = 6;
t.1 = 7;
println!("{}", @t.0@);`}
  />
  <SliceListing
    code={`let mut t = (0, 1, 2);
t = (3, 4, 5);
t.0 = 6;
t.1 = 7;
println!("{}", @t.2@);`}
  />
</Row>

In this program, when slicing on `t`, changing the value of a field of a structure changes the value of the whole structure, so `t.1 = 7` is part of the slice on `t`. However, when slicing on `t.0`, the path `t.0` is disjoint from the path `t.1`, so `t.1 = 7` is not part of the slice on `t.0`. Similarly, when slicing on `t.2`, the only relevant assignment is `t = (3, 4, 5)`. More generally, a place conflicts with another place if either's path is a prefix of the other's. For instance, `t.0` conflicts with both `t` (parent) and `t.0.1` (child) but not `t.1` (sibling). This leads to the first slicing principle:

<Principle
  type={"places"}
  text={"A mutation to a place is a mutation to all conflicting places."}
/>

This principle provides an intuition for making an algorithm that constructs slices. For instance, take the last example above on the left. On line 4, when `t.1` is mutated, that mutation is registered as part of the slice on every conflicting place, specifically `t` and `t.1`.

</SubSection>

<SubSection title="References" name="sec:pointers">
Pointers are the first major challenge for slicing. A mutation to a dereferenced pointer
is a mutation to any place that is possibly pointed-to, so such places must be known to
the slicer. For example:

<Wrap align="right">
  <SliceListing
    code={`let mut x = 1;
let y = &mut x;
*y = 2;
let z = &x;
println!("{}", @*z@);`}
  />
</Wrap>

Rust has two distinct types of pointers, which are called <q>references</q> to distinguish them
from <q>raw pointers</q> with C-like behavior (discussed in @[sec:intmut]
). For a given type `T`, there are immutable references of type `&T`, and
mutable references of type `&mut T` which correspond respectively to the expressions
`&x` and `&mut x`. Because `y` points to `x`, then the mutation
through `y` is relevant to the read of `*z`. We refer to the left-hand side of
assignment statements like `*y` as <q>place expressions</q>, since they could include
dereferences.

The task of determining what a reference can point-to is called _pointer analysis_
. While many methods exist for pointer analysis @[smaragdakis2015pointer], our
first key insight is that Rust's ownership types implicitly perform a kind of modular
pointer analysis that we can leverage for slicing. To understand why, we first need to
describe two ingredients: the goal, i.e. what ownership is trying to accomplish, and the
mechanism, i.e. how ownership-checking is implemented in the type system.

The core goal of ownership is eliminating simultaneous aliasing and mutation. In Rust,
achieving this goal enables the use of references without garbage collection while
retaining memory safety. For instance, these three classes of errors are all caught at
compile-time:

<Row>
  <Listing
    code={`// Dangling reference
let p = {
let x = 1; &x
};
let y = *p;`}
  />
  <Listing
    code={`// Use-after-free
let d = tempdir();
let d2 = &d;
d.close();
let p = d2.path();`}
  />
  <Listing
    code={`// Iterator invalidation
let mut v = vec![1,2];
for x in v.iter() {
v.push(*x);
}`}
  />
</Row>

From left-to-right: the dangling references is caught because `x` is deallocated at
the end of scope on line 4, which is a mutation, conflicting with the alias `&x`. The
use-after-free is caught because `d.close()` requires ownership of `d`, which
prevents an alias `d2` from being live. The iterator invalidation case is subtler:
`x` is a pointer to data within `v`. However, `v.push(*x)` could resize
`v` which would copy/deallocate all vector elements to a new heap location,
invalidating all pointers to `v`. Hence `v.push(*x)` is a simultaneous mutation
and alias of the vector.

Catching these errors requires understanding which places are pointed by which references.
For instance, knowing that `x` points to an element of `v` and not just any
arbitrary `i32`. The key mechanism behind these ownership checks is
_lifetimes_.

<Wrap align="left">
  <Listing
    code={`let mut x: i32 = 1;
let y: &'1 i32 = &'0 mut x;
*y = 2;
let z: &'3 i32 = &'2 x;
println!("{}", *z);`}
  />
</Wrap>

Each reference expression and type has a corresponding lifetime, written explicitly in the
syntax `'n` on the left, where `n` is an arbitrary and unique number. The name
"lifetime" implies a model of lifetimes as the live range of the reference. Prior work on
region-based memory management like @[tofte1997region; full] and @[grossman2002region; full] use this model.

However, recent work from @[polonius; full] and @[weiss2019oxide; full] have
devised an alternative model of lifetimes as "provenances" or "origins" that more directly
correspond to a pointer analysis. In essence, a lifetime is the set of places that a
reference could point-to. For the above example, that would be `'n = x ` for all
`n`, because each reference points to `x`. As a more interesting example,
consider the code on the left.

<Wrap align="left">
  <Listing
    code={`let mut x = 1;
let mut y = 2;
let z: &'2 mut i32 = if true {
&'0 mut x
} else {
&'1 mut y
};
let w: &'4 mut i32 = &'3 mut *z;
*w = 1;`}
  />
</Wrap>

There, lifetimes for borrow expressions are assigned to the place being borrowed, so
`'0 = x ` and `'1 = y `. Because `z` could be assigned to either reference,
then `'2 = '0 âˆª '1 = {x, y}`. An expression of the form `& *p` is called a
"reborrow", as the underlying address is being passed from one reference to another. To
register that a reference is reborrowed, the reborrowed place is also added to the
lifetime, so `'3 = '4 = {x, y, *z}`. More generally:

<Principle
  type={"references"}
  text={
    "The lifetime of a reference contains all potential aliases of what the reference points-to."
  }
/>

In the context of slicing, then to determine which places could be modified by a
particular assignment, one only needs to look up the aliases in the lifetime of
references. For instance, `*w = 1` would be part of a slice on `*z`, because
`*z` is in the lifetime `'4` of `w`.

</SubSection>

<SubSection title="Function calls" name="sec:funcalls">

The other major challenge for slicing is function calls. For instance, consider slicing a
call to an arbitrary function `f` with various kinds of inputs: <Footnote> Why is `String::from` needed? The literal `"Hello world"` has type `&'static st`, meaning an immutable reference to the binary's string pool which lives forever. The function `String::from` converts the immutable reference into a value of type `String`, which stores its contents on the heap and allows the string to be mutated. </Footnote>

<Wrap align="left">
  <Listing
    code={`let x = String::from("x");
let y = String::from("y");
let mut z = String::from("z");
let w = f(x, &y, &mut z);
println!("{} {} {}", y, z, w);`}
  />
</Wrap>

The standard approach to slicing `f` would be to inspect the definition of `f`,
and recursively slice it by translating the slicing criteria from caller to callee (e.g.
see @[weiser1982programmers; full] for an example). However, our goal is to avoid
using the definition of `f` (i.e. a whole-program analysis) for the reasons described
in @[sec:intro].

To modularly slice through function calls, we need to approximate the effects of `f`
in a manner that is sound, but also as precise as possible. Put another way, what
mutations could possibly occur as a result of calling `f`? Consider the three cases
that arise in the code above.

- Passing a value `x` of type `String` (or generally of type `T`) moves the value into `f`.
  Therefore it is an ownership error to refer to `x` after calling `f` and we do not need to
  consider slices on `x` after `f`.
- Passing a value `y` of type `&String` (or `&T`) passes an immutable reference. Immutable
  references cannot be mutated, therefore `y` cannot change in `f`.
  <Footnote>
    A notable detail to the safety of immutable references is that immutability is transitive. For
    instance, if `b = &mut a` and `c = &b`, then `a` is guaranteed not to be mutated through `c`.
    This stands in contrast to other languages with pointers like C and C++ where the `const`
    keyword only protects values from mutation at the top-level, and not into the interior fields.
  </Footnote>
- Passing a value `z` of type `&mut String` (or `&mut T`) passes a mutable reference, which could
  possibly be mutated. This case is therefore the only observable of effect `f` apart from its
  return value.

Without inspecting `f`, we cannot know how a mutable reference is modified, so we
have to conservatively assume that every argument was used as input to a mutation.
Therefore the modular slice of each variable looks as in the snippets below:

<Row>
  <SliceListing
    prelude={"let f = |x: String, y: &String, z: &mut String| -> usize { 0 };"}
    code={`let x = String::from("x");
let y = String::from("y");
let mut z = String::from("z");
let w = f(x, &y, &mut z);
println!("{}", @y@);`}
  />
  <SliceListing
    prelude={"let f = |x: String, y: &String, z: &mut String| -> usize { 0 };"}
    code={`let x = String::from("x");
let y = String::from("y");
let mut z = String::from("z");
let w = f(x, &y, &mut z);
println!("{}", @z@);`}
  />
  <SliceListing
    prelude={"let f = |x: String, y: &String, z: &mut String| -> usize { 0 };"}
    code={`let x = String::from("x");
let y = String::from("y");
let mut z = String::from("z");
let w = f(x, &y, &mut z);
println!("{}", @w@);`}
  />
</Row>

Note that like `z` (middle), the return value `w` (right) is also assumed to be
influenced by every input to `f`. Implicit in these slices are additional assumptions
about the limitations of `f`. For example, in C, a function could manufacture a
pointer to the stack frame above it and mutate the values, meaning `f` could mutate
`y` (even if `y` was not an input!). Similarly, functions could potentially read
arbitrary data (e.g. global variables) that would influence mutations apart from just the
arguments.

However, allowing such pointer manipulation would easily break ownership safety, since
fundamentally it permits unchecked aliasing. Hence, our principle:

<Principle
  type="function calls"
  text="When calling a function, (a) only mutable references in the arguments can be mutated, and (b) the mutations and return value are only influenced by the arguments."
/>

This principle is essentially a worst-case approximation to the function's effects. It is
the core of how we can modularly slice programs, because a function's definition does not
have to be inspected to analyze what it can mutate.

A caveat to this principle is global variables: (@[prin:function calls]-a) is not true with mutable globals, and (@[prin:function calls]-b) is not true with read-only globals. Mutable globals are disallowed by the rules of ownership, as
they are implicitly aliased and hence disallowed from being mutable. However, read-only globals are ownership-safe
(and hence permitted in Rust). For simplicity we do not consider read-only globals in this work.

Another notable detail is the interaction of function calls and lifetimes. Pointer
analysis, like slicing, has historically been done via whole-program analysis for maximum
precision. However, Rust can analyze lifetimes (and subsequently what references point-to)
modularly just by looking at the type signature of a called function using
_lifetime parameters_ . Consider the function `Vec::get_mut` that returns a
mutable reference to an element of a vector. For instance, `vec![5, 6].get_mut(0)`
returns a mutable reference to the value 5. This function has the type signature:

<Center style={{ margin: "1rem 0" }}>
  `Vec::get_mut   :   forall 'a, T . (&'a mut Vec<T>, usize) -> &'a mut T`
</Center>

Because this type signature is parametric in the lifetime `'a`, it can express the
constraint that the output reference `&'a mut T` must have the same lifetime as the
input reference `&'a mut Vec<T>`. Therefore the returned pointer is known to
point to the same data as the input pointer, but without inspecting the definition of
`get_mut`.

</SubSection>

<SubSection title="Interior mutability" name="sec:intmut">

The previous sections describe a slicing strategy for the subset of Rust known as "safe
Rust", that is programs which strictly adhere to the rules of ownership. Importantly, Rust
also has the `unsafe` feature that gives users access to raw pointers, or pointers
with similar unchecked behavior to C. Most commonly, `unsafe` code is used to
implement APIs that satisfy ownership, but not in a manner that is deducible by the type
system. For example, shared mutable state between threads:

<Wrap align="left">
  <Listing
    code={`let value = Arc::new(Mutex::new(0));
let value_ref = value.clone();
thread::spawn(move || { 
*value_ref.lock().unwrap() += 1; 
}).join().unwrap();
assert!(*value.lock().unwrap() == 1);`}
  />
</Wrap>

In this snippet, two threads have ownership over two values of type `Arc<Mutex<i32>>` which internally point to the same number. Both threads can call
`Mutex::lock` which takes an immutable reference to an `&Mutex<i32>` and returns a mutable reference `&mut i32` to the data inside. <Footnote>Technically the returned type is a `LockResult<MutexGuard<'a, i32>>` but the distinction isn't relevant here. </Footnote> This nominally violates ownership, as the data is aliased (shared by two threads) and mutable (both
can mutate).

The mutex is ownership-safe only because its implementation ensures that both threads
cannot _simultaneously_ access the underlying value in accordance with the system
mutex's semantics. For our purposes, the aliasing between `value` and
`value_ref` is not possible to observe using the type system alone. For example, in
our algorithm, slicing on `value` would _not_ include mutations to
`value_ref`. This is because the data inside the mutex has type `*mut i32` (a
raw pointer), and without a lifetime attached, our algorithm has no way to determine
whether `value` and `value_ref` are aliases just by inspecting their types.

More broadly, modular slicing is only sound for safe Rust. The point of this work is to
say: when a program can be statically determined to satisfy the rules of ownership, then
modular slicing is sound. The principles above help clarify the specific assumptions made
possible by ownership, which are otherwise impossible to make in languages like C or Java.

@[astrauskas2020programmers; full] found that 76.4% of published Rust projects contain no unsafe
code, suggesting that safe Rust is more common than not. However, their study does not account for safe
Rust built on internally-unsafe abstractions like `Mutex`, so it is difficult to estimate the true likelihood
of soundness in practice. We discuss the issue of slicing with unsafe code further in
@[sec:whole-vs-mod].

</SubSection>

</Section>

<Section title="Formal Model" name="sec:model">
To build an algorithm from these principles, we first need a formal model to describe and
reason about the underlying language. Rather than devise our own, we build on the work of
@[weiss2019oxide; full] : Oxide is a model of (safe) Rust's surface language with a
formal static and dynamic semantics, along with a proof of syntactic type soundness.
Importantly, Oxide uses a provenance model of lifetimes which we leverage for our slicing
algorithm.

We will incrementally introduce the aspects of Oxide's syntax and semantics as necessary to
understand our principles and algorithm. We describe Oxide's syntax (@[sec:syn]), static semantics (@[sec:statsem]) and dynamic semantics (@[sec:dynsem]), and then apply these concepts to formalize the slicing principles of the previous section
(@[sec:formal_principles]).

<SubSection title="Syntax" name="sec:syn">
@[fig:oxide_syntax] shows a subset of Oxide's syntax along with a labeled
example. An Oxide program consists of a set of functions $\fenv$ (the "global
environment"), where each function body is an expression $\expr$.

<Figure name="fig:oxide_syntax">
<Subfigure name="fig:oxide_syntax_bnf">
  <Oxide.Bnf layout={{ columns: 2, cutoff: 9 }} />
  <Expandable prompt={<>Rest of the grammar...</>}>
    <OxideExtra.Bnf />
  </Expandable>
  <Caption>Subset of Oxide syntax, reproduced from @[weiss2019oxide; full]. The only difference in this subset is that closures are eliminated and functions are simplified to take one argument.</Caption>
</Subfigure>
<Subfigure name="fig:oxide_syntax_example">
  <SyntaxDiagram />
  <Caption>Syntactic forms and corresponding metavariables labeled in context of an example</Caption>
</Subfigure>
<Caption>Formal elements of Oxide and their explanation (excerpts).</Caption>
</Figure>
</SubSection>

</Section>

<References bibtex={bibtex} />

</Document>
